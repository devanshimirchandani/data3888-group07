---
title: "finding summaru"
author: "T"
date: "2025-05-23"
output: html_document
editor_options: 
  markdown: 
    wrap: sentence
---

```{r}
library(tidyverse)
library(reshape2)
```

# combined(GSE10810, GSE17907) findings summary

```{r}
library(dplyr)
library(reshape2)
library(ggplot2)

combine_metrics <- data.frame(
  Genes = rep(c(30, 50, 80, 110), each = 3),
  Model = rep(c("SVM", "KNN", "RF"), times = 4),
  Accuracy = c(0.619, 0.524, 0.571,
               0.571, 0.524, 0.619,
               0.619, 0.571, 0.619,
               0.667, 0.524, 0.571),
  Kappa = c(0.408, 0.281, 0.368,
            0.325, 0.314, 0.425,
            0.378, 0.372, 0.447,
            0.481, 0.367, 0.366),
  Macro_F1 = c(0.75, 0.663, 0.558,
               0.703, 0.706, 0.607,
               0.75, 0.777, 0.642,
               0.654, 0.587, 0.583),
  Precision = c(0.462, 0.417, 0.427,
                0.457, 0.471, 0.489,
                0.511, 0.4, 0.491,
                0.654, 0.539, 0.435),
  Recall = c(0.409, 0.353, 0.416,
             0.373, 0.353, 0.443,
             0.401, 0.381, 0.478,
             0.463, 0.388, 0.45),
  Sensitivity = c(0.409, 0.353, 0.416,
                  0.373, 0.353, 0.443,
                  0.401, 0.381, 0.478,
                  0.463, 0.388, 0.45),
  Specificity = c(0.856, 0.823, 0.847,
                  0.832, 0.836, 0.859,
                  0.842, 0.852, 0.868,
                  0.871, 0.859, 0.842),
  Balanced_Accuracy = c(0.632, 0.588, 0.632,
                        0.603, 0.595, 0.651,
                        0.621, 0.616, 0.673,
                        0.667, 0.624, 0.646)
)



# View the table
print(combine_metrics)

# Add an identifier for easier plotting
combine_metrics$Config <- paste(combine_metrics$Model, combine_metrics$Genes, sep = "_")

# Select top 5 models by Balanced Accuracy
top5 <- combine_metrics %>%
  arrange(desc(Balanced_Accuracy)) %>%
  head(5)

# Reshape to long format for ggplot
top5_long <- melt(top5, id.vars = c("Model", "Genes", "Config"))

# Plot heatmap
ggplot(top5_long, aes(x = variable, y = Config, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "#d07095", name = "Metric Value") +
  labs(title = "Performance Heatmap of Top 5 Models",
       x = "Metric",
       y = "Model (Config)") +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

# Best Model – SVM with top 110 genes

-   This model achieves the highest Accuracy (0.667) and Kappa (0.481), indicating strong predictive performance and reliable agreement beyond chance.

-   It also has the highest Balanced Accuracy (0.667), meaning it maintains good sensitivity and specificity balance.

-   Although some models have higher Macro F1 (e.g., SVM at 30 genes with 0.75), the overall combination of metrics favors the SVM with 110 genes for consistent and balanced performance.

# GSE17907 findings summary

```{r}
library(ggplot2)
library(reshape2)
library(dplyr)

# Evaluation metrics for GSE17907 dataset
gse17907_metrics <- data.frame(
  Genes = rep(c(30, 50, 80, 110), each = 3),
  Model = rep(c("SVM", "KNN", "RF"), times = 4),
  Accuracy = c(0.583, 0.667, 0.667,
               0.5, 0.667, 0.667,
               0.583, 0.583, 0.667,
               0.583, 0.667, 0.667),
  Kappa = c(0, 0.262, 0.262,
            0.04, 0.262, 0.262,
            0, 0.143, 0.262,
            0, 0.262, 0.262),
  Macro_F1 = c(0.737, 0.722, 0.722,
               0.646, 0.722, 0.722,
               0.737, 0.686, 0.722,
               0.737, 0.722, 0.722),
  Precision = c(0.583, 0.818, 0.818,
                0.519, 0.818, 0.818,
                0.583, 0.533, 0.818,
                0.583, 0.818, 0.818),
  Recall = c(0.25, 0.375, 0.375,
             0.304, 0.375, 0.375,
             0.25, 0.339, 0.375,
             0.25, 0.375, 0.375),
  Sensitivity = c(0.25, 0.375, 0.375,
                  0.304, 0.375, 0.375,
                  0.25, 0.339, 0.375,
                  0.25, 0.375, 0.375),
  Specificity = c(0.75, 0.8, 0.8,
                  0.75, 0.8, 0.8,
                  0.75, 0.775, 0.8,
                  0.75, 0.8, 0.8),
  Balanced_Accuracy = c(0.5, 0.588, 0.588,
                        0.527, 0.588, 0.588,
                        0.5, 0.557, 0.588,
                        0.5, 0.588, 0.588)
)


# Add unique Config column
gse17907_metrics$Config <- paste(gse17907_metrics$Model, gse17907_metrics$Genes, sep = "_")

# Remove duplicated rows just in case (optional but safe)
gse17907_metrics <- distinct(gse17907_metrics)

# Select top 5 *distinct* models by Balanced Accuracy
top5 <- gse17907_metrics %>%
  arrange(desc(Balanced_Accuracy)) %>%
  slice_head(n = 5)

# Reshape to long format for heatmap
top5_long <- melt(top5, id.vars = c("Model", "Genes", "Config"))

# Plot heatmap
ggplot(top5_long, aes(x = variable, y = Config, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "#d07095", name = "Metric Value") +
  labs(title = "Performance Heatmap of Top 5 Models",
       x = "Metric",
       y = "Model (Config)") +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

# Best Model – KNN or RF across multiple gene sets (30, 50, 80, 110 genes)

-   These models consistently achieve the highest Accuracy of 0.667.

-   They have the highest Kappa values (0.262) in this dataset, indicating moderate agreement beyond chance.

-   They maintain strong Macro F1 scores (0.722), showing a good balance between precision and recall.

-   Their Balanced Accuracy of 0.588 suggests reasonable performance on both positive and negative classes.

Although the SVM models occasionally have decent Macro F1, their lower accuracy and Kappa values indicate less reliable overall performance.

```{r}
library(ggplot2)
library(reshape2)
library(dplyr)

# Evaluation metrics from confusion matrices
gse15852_metrics <- data.frame(
  Genes = rep(c(30, 50, 80, 110), each = 3),
  Model = rep(c("SVM", "KNN", "RF"), times = 4),
  Accuracy = c(0.474, 0.526, 0.526,
               0.474, 0.421, 0.421,
               0.474, 0.474, 0.526,
               0.579, 0.474, 0.526),
  Kappa = c(0, 0.162, 0.17,
            0.031, -0.045, -0.056,
            0.095, 0.116, 0.17,
            0.321, 0.116, 0.153),
  Macro_F1 = c(0.643, 0.61, 0.556,
               0.667, 0.615, 0.615,
               0.533, 0.783, 0.486,
               0.659, 0.473, 0.485),
  Precision = c(0.474, 0.521, 0.517,
                0.25, 0.157, 0.235,
                0.344, 0.161, 0.425,
                0.364, 0.226, 0.448),
  Recall = c(0.25, 0.333, 0.322,
             0.25, 0.222, 0.222,
             0.306, 0.25, 0.3,
             0.417, 0.272, 0.3),
  Sensitivity = c(0.25, 0.333, 0.322,
                  0.25, 0.222, 0.222,
                  0.306, 0.25, 0.3,
                  0.417, 0.272, 0.3),
  Specificity = c(0.75, 0.789, 0.789,
                  0.759, 0.742, 0.739,
                  0.774, 0.791, 0.796,
                  0.835, 0.784, 0.789),
  Balanced_Accuracy = c(0.5, 0.561, 0.556,
                        0.505, 0.482, 0.481,
                        0.54, 0.521, 0.548,
                        0.626, 0.528, 0.545)
)

# Add Config column
gse15852_metrics$Config <- paste(gse15852_metrics$Model, gse15852_metrics$Genes, sep = "_")

# Select top 5 models by Balanced Accuracy
top5 <- gse15852_metrics %>%
  arrange(desc(Balanced_Accuracy)) %>%
  head(5)

# Reshape to long format for heatmap
top5_long <- melt(top5, id.vars = c("Model", "Genes", "Config"))

# Plot heatmap
ggplot(top5_long, aes(x = variable, y = Config, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "#d07095", name = "Metric Value") +
  labs(title = "Performance Heatmap of Top 5 Models",
       x = "Metric",
       y = "Model (Config)") +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

# Best Model – SVM with top 110 genes 

-   This model achieves the highest Accuracy (0.579) and Kappa (0.321) values in this dataset, indicating the strongest agreement beyond chance.

-   It also has the highest Balanced Accuracy (0.626), which means it handles class imbalance better than others.

-   While the KNN model at 80 genes has the highest Macro F1 (0.783), it falls behind in accuracy and balanced accuracy, suggesting less consistent performance.
