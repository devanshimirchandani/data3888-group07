---
title: "COMBINED V2"
output: html_document
date: "2025-05-06"
---

```{r}
library(GEOquery) 
library(R.utils)
library(reshape2)
library(ggplot2)
library(limma)
library(dplyr)
library(edgeR)
library(Biobase)
library(dplyr)
library(sva)
library(caret)
library(e1071)  # for SVM
library(randomForest)


```

```{r}
gse <- getGEO("GSE10810")
gse10810 <- gse[[1]]

gse <- getGEO("GSE17907")
gse17907 <- gse[[1]]

gse <- getGEO("GSE20711")
gse20711 <- gse[[1]]

gse <- getGEO("GSE42568")
gse42568 <- gse[[1]]

gse <- getGEO("GSE61304")
gse61304  <- gse[[1]]

gse <- getGEO("GSE15852")
gse15852  <- gse[[1]]
```

```{r}
pData(gse10810) # characteristics_ch1.3
pData(gse17907) # grade sbr:ch1
pData(gse20711) # characteristics_ch1.3
pData(gse42568) # characteristics_ch1.4
pData(gse61304) # characteristics_ch1.2
pData(gse15852) # characteristics_ch1.2
```
```{r}
dim(exprs(gse10810))
dim(exprs(gse17907))

dim(exprs(gse15852))
```
```{r}
# merged
dim(exprs(gse20711))
dim(exprs(gse42568))
dim(exprs(gse61304))

pData(gse20711) # characteristics_ch1.3
pData(gse42568) # characteristics_ch1.4
pData(gse61304) # characteristics_ch1.2
```


```{r}
# Function to extract and standardize grade into correct names
standardize_grade <- function(grades, pattern, replacements, remove_na = TRUE) {
  grades <- tolower(grades)
  for (i in seq_along(pattern)) {
    grades <- gsub(pattern[i], replacements[i], grades)
  }
  grades <- gsub(".*(\\b[0-3]\\b).*", "\\1", grades)  # Extract grade number if embedded
  grades[!grades %in% c("0", "1", "2", "3")] <- NA     # Drop anything unexpected
  if (remove_na) {
    grades <- as.numeric(grades)
  }
  
  # Map grades to full names
  grade_names <- c("0" = "Normal", "1" = "Grade1", "2" = "Grade2", "3" = "Grade3")
  grades <- grade_names[as.character(grades)]  # Map numbers to grade names
  
  return(grades)
}

### GSE10810
pdata10810 <- pData(gse10810)
grades10810 <- pdata10810$characteristics_ch1.3
# Patterns to handle: "grade: 0", "grade: i", "grade: ii", "grade: iii"
pdata10810$grade <- standardize_grade(
  grades10810,
  c("grade: 0", "grade: i\\b", "grade: ii\\b", "grade: iii\\b"),
  c("0", "1", "2", "3")
)
pdata10810 <- pdata10810[!is.na(pdata10810$grade), ]

### GSE17907
pdata17907 <- pData(gse17907)
grades17907 <- pdata17907$`grade sbr:ch1`
pdata17907$grade <- standardize_grade(
  grades17907,
  c("--"),
  c("0")
)
pdata17907 <- pdata17907[!is.na(pdata17907$grade), ]

### GSE20711
pdata20711 <- pData(gse20711)
grades20711 <- pdata20711$characteristics_ch1.3
pdata20711$grade <- standardize_grade(
  grades20711,
  c("grade: na", "grade: "),
  c(NA, "")
)
pdata20711 <- pdata20711[!is.na(pdata20711$grade), ]

### GSE42568
pdata42568 <- pData(gse42568)
grades42568 <- pdata42568$characteristics_ch1.4
pdata42568$grade <- standardize_grade(
  grades42568,
  c("grade: na", "grade: "),
  c(NA, "")
)
pdata42568 <- pdata42568[!is.na(pdata42568$grade), ]

### GSE61304
pdata61304 <- pData(gse61304)
grades61304 <- pdata61304$`characteristics_ch1.2`
pdata61304$grade <- standardize_grade(
  grades61304,
  c("tumor grade: na", "tumor grade: g1", "tumor grade: g2", "tumor grade: g3"),
  c(NA, "1", "2", "3")
)
pdata61304 <- pdata61304[!is.na(pdata61304$grade), ]

### GSE15852
pdata15852 <- pData(gse15852)
grades15852 <- pdata15852$`characteristics_ch1.2`
pdata15852$grade <- standardize_grade(
  grades15852,
  c("grade: normal", "grade: grade 1", "grade: grade 2", "grade: grade 3"),
  c("0", "1", "2", "3")
)
pdata15852 <- pdata15852[!is.na(pdata15852$grade), ]


```

```{r}
pdata10810
pdata17907
pdata20711
pdata42568
pdata61304
pdata15852

```

```{r}
# Helper function to process ExpressionSet
process_eset <- function(eset, min_avg_expr = 5) {
  exprs_mat <- exprs(eset)
  
  # Filter lowly expressed genes
  keep_exprs <- rowMeans(exprs_mat) >= min_avg_expr
  exprs_mat <- exprs_mat[keep_exprs, , drop = FALSE]
  
  # Remove duplicate genes (based on rownames)
  unique_rows <- !duplicated(rownames(exprs_mat))
  exprs_mat <- exprs_mat[unique_rows, , drop = FALSE]

  # Subset the ExpressionSet to match filtered expression matrix
  eset_filtered <- eset[rownames(exprs_mat), ]
  return(eset_filtered)
}

# Apply to each dataset and keep same names
gse10810 <- process_eset(gse10810)
gse17907 <- process_eset(gse17907)
gse20711 <- process_eset(gse20711)
gse42568 <- process_eset(gse42568)
gse61304 <- process_eset(gse61304)
gse15852 <- process_eset(gse15852)

```


```{r}

# 1. Expression sets
expr_list <- list(

  gse10810 = exprs(gse10810),
  gse17907 = exprs(gse17907),
  gse20711 = exprs(gse20711),
  gse42568 = exprs(gse42568),
  gse61304 = exprs(gse61304)
)

# 2. Phenotype sets
pdata_list <- list(

  pdata10810,
  pdata17907,
  pdata20711,
  pdata42568,
  pdata61304

)

# 3. Fix phenotype rownames using geo_accession if present
pdata_list <- lapply(pdata_list, function(p) {
  if ("geo_accession" %in% colnames(p)) {
    rownames(p) <- p$geo_accession
  }
  return(p)
})

# Reassign corrected pdata

# 1. Assign pdata
pdata10810 <- pdata_list[[1]]
pdata17907 <- pdata_list[[2]]
pdata20711 <- pdata_list[[3]]
pdata42568 <- pdata_list[[4]]
pdata61304 <- pdata_list[[5]]

# 2. Create pheno_list with dataset names
pheno_list <- list(
  gse10810 = pdata10810,
  gse17907 = pdata17907,
  gse20711 = pdata20711,
  gse42568 = pdata42568,
  gse61304 = pdata61304
)

# 3. Extract grade list and track batch
grade_list <- Map(function(expr, pheno, batch_name) {
  sample_names <- colnames(expr)
  matched_pheno <- pheno[sample_names, , drop = FALSE]
  grades <- matched_pheno$grade
  names(grades) <- sample_names
  # Track batch
  data.frame(
    sample = sample_names,
    grade = grades,
    batch = batch_name,
    stringsAsFactors = FALSE
  )
}, expr_list, pheno_list, names(pheno_list))

# 4. Combine all grade + batch info into metadata
metadata <- do.call(rbind, grade_list)

# 5. Clean sample names to remove prefixes (e.g., "gse10810.")
metadata$sample <- sub(".*\\.", "", metadata$sample)

# 6. Combine expression matrices
expr_dfs <- lapply(expr_list, function(mat) {
  df <- as.data.frame(mat)
  df$gene <- rownames(mat)
  df
})

merged_expr <- Reduce(function(x, y) full_join(x, y, by = "gene"), expr_dfs)
rownames(merged_expr) <- merged_expr$gene
merged_expr$gene <- NULL

# 7. Ensure metadata matches expression matrix columns
colnames(merged_expr) <- sub(".*\\.", "", colnames(merged_expr))  # Match cleaned sample names
metadata <- metadata[match(colnames(merged_expr), metadata$sample), ]

# 8. Final check
stopifnot(all(metadata$sample == colnames(merged_expr)))

# âœ… Outputs
metadata
dim(merged_expr)
table(metadata$batch)
table(metadata$grade)

summary(as.vector(merged_expr))

```
```{r}
metadata <- metadata[!is.na(metadata$grade), ]
metadata
# ðŸ§¼ Remove corresponding columns from merged_expr
merged_expr <- merged_expr[, metadata$sample]
anyNA(merged_expr)
sum(is.na(merged_expr))
merged_expr <- merged_expr[complete.cases(merged_expr), ]
merged_expr

table(metadata$grade)
```

```{r}


# Run PCA
pca <- prcomp(t(merged_expr), scale. = TRUE)

# Create a data frame for plotting
pca_df <- data.frame(
  PC1 = pca$x[, 1],
  PC2 = pca$x[, 2],
  batch = metadata$batch,
  grade = metadata$grade
)

# Plot PCA, color by batch
ggplot(pca_df, aes(x = PC1, y = PC2, color = batch)) +
  geom_point(size = 2) +
  theme_minimal() +
  labs(title = "PCA: Color by Batch")

# Optional: facet by condition
ggplot(pca_df, aes(x = PC1, y = PC2, color = grade)) +
  geom_point(size = 2) +
  facet_wrap(~batch) +
  theme_minimal() +
  labs(title = "PCA: Faceted by Batch")

```

```{r}
log_merged <- log2(merged_expr + 1)



merged_expr[merged_expr < 0] <- 0  # Replace negative values with 0


# Create DGEList object from raw counts
dge <- DGEList(counts = merged_expr)

# Normalize the counts (TMM method)
dge <- calcNormFactors(dge)

# Apply the normalization factors
normalized_expr <- cpm(dge, log = FALSE)  # Output in counts per million

# Log2 CPM transformation (recommended for limma)
log2_expr <- cpm(dge, log = TRUE)



train_idx <- sample(seq_len(ncol(normalized_expr)), size = 0.7 * ncol(normalized_expr))

# Create training and test sets
expr_train <- normalized_expr[, train_idx]
expr_test <- normalized_expr[, -train_idx]

metadata_train <- metadata[match(colnames(expr_train), metadata$sample), ]
metadata_test <- metadata[metadata$sample %in% colnames(expr_test), ]

# Reorder metadata_train to match expr_train sample order
# Remove genes with zero variance in any batch



```

```{r}
batch <- metadata_train$batch  # Replace 'batch' with the actual batch column name
grade <- factor(metadata_train$grade)  # Replace with actual condition column
mod <- model.matrix(~ grade)  # Model for the biological variable


remove_zero_var_genes <- function(expr, batch) {
  keep <- apply(expr, 1, function(gene) {
    all(tapply(gene, batch, function(x) var(x) > 0))
  })
  expr[keep, ]
}

expr_train_clean <- remove_zero_var_genes(expr_train, batch)
# Should return: Factor or atomic vector, length == ncol(expr_train)

# Perform ComBat batch correction
combat <- ComBat(dat = expr_train_clean, batch = batch, mod = mod)


# Check the dimensions of combat_train
dim(combat) 
```


```{r}
library(ggplot2)
library(reshape2)

# Function to run PCA and return a dataframe
get_pca_df <- function(expr_mat, metadata, prefix = "") {
  pca <- prcomp(t(expr_mat), scale. = TRUE)
  pca_df <- as.data.frame(pca$x[, 1:2])  # First two PCs
  pca_df$sample <- rownames(pca_df)
  pca_df <- merge(pca_df, metadata, by = "sample")
  colnames(pca_df)[1:3] <- paste0(prefix, c("PC1", "PC2", "sample"))
  return(pca_df)
}

# PCA before batch correction
pca_before <- get_pca_df(log2_expr, metadata, prefix = "before_")

# PCA after batch correction
pca_after <- get_pca_df(combat, metadata, prefix = "after_")


```

```{r}
# Plot before batch correction
ggplot(pca_before, aes(x = before_PC1, y = before_PC2, color = batch)) +
  geom_point(size = 2) +
  labs(title = "PCA Before Batch Correction", x = "PC1", y = "PC2") +
  theme_minimal()

# Plot after batch correction
ggplot(pca_after, aes(x = after_PC1, y = after_PC2, color = batch)) +
  geom_point(size = 2) +
  labs(title = "PCA After Batch Correction", x = "PC1", y = "PC2") +
  theme_minimal()

```


```{r}
library(smotefamily)

# Transpose so samples are rows
expr_t <- t(combat)
expr_df <- as.data.frame(expr_t)
expr_df$grade <- metadata_train$grade[match(rownames(expr_df), metadata_train$sample)]

# Convert grade to factor
expr_df$grade <- as.factor(expr_df$grade)

# Apply SMOTE (over-sampling only)
# dup_size controls how many synthetic samples to make per minority sample
smote_result <- SMOTE(X = expr_df[, -ncol(expr_df)],
                      target = expr_df$grade,
                      K = 5,
                      dup_size = 5)  # try 5â€“10

# SMOTE returns a list with $data
expr_smote <- smote_result$data

# Extract new metadata and expression matrix
metadata_train <- data.frame(
  sample = paste0("SMOTE_", seq_len(nrow(expr_smote))),
  grade = expr_smote$class
)

expr_balanced <- t(as.matrix(expr_smote[, -ncol(expr_smote)]))
colnames(expr_balanced) <- metadata_train$sample

stopifnot(all(colnames(expr_balanced) == metadata_train$sample))
table(metadata_train$grade)
```

```{r}
# Map grade levels to numeric trend
grade_map <- c("Normal" = 0, "Grade1" = 1, "Grade2" = 2, "Grade3" = 3)
grade_num <- grade_map[as.character(metadata_train$grade)]

design <- model.matrix(~ grade_num)  # includes intercept + trend

fit <- lmFit(expr_balanced, design)
fit <- eBayes(fit)

top_genes <- topTable(
  fit,
  coef = "grade_num",  # test for trend
  adjust = "BH",
  p.value = 0.05,      # FDR threshold
  lfc = 0.5,           # log2 fold-change threshold
  number = Inf
)

head(top_genes)
nrow(top_genes)  # number of significant genes

top_30 <- rownames(top_genes)[1:30]
top_50 <- rownames(top_genes)[1:50]
top_80 <- rownames(top_genes)[1:80]
top_110 <- rownames(top_genes)[1:110]

```



```{r}
# Labels (as factor for classification)
labels <- as.factor(metadata_train$grade)
evaluate_models <- function(feature_genes, expr_data, labels) {
  features <- t(expr_data[feature_genes, ])  # transpose: samples as rows
  data <- data.frame(features)
  data$label <- labels
  
  # Set up cross-validation
  control <- trainControl(method = "cv", number = 10)
  
  # KNN
  set.seed(1)
  knn_model <- train(label ~ ., data = data, method = "knn", trControl = control)
  
  # Random Forest
  set.seed(1)
  rf_model <- train(label ~ ., data = data, method = "rf", trControl = control)
  
  # SVM (linear kernel)
  set.seed(1)
  svm_model <- train(label ~ ., data = data, method = "svmLinear", trControl = control)
  
  list(
    KNN = knn_model,
    RF = rf_model,
    SVM = svm_model
  )
}


```




```{r}
results_30 <- evaluate_models(top_30, expr_balanced, labels)
results_50 <- evaluate_models(top_50, expr_balanced, labels)
results_80 <- evaluate_models(top_80, expr_balanced, labels)
results_110 <- evaluate_models(top_110, expr_balanced, labels)

```


```{r}
results_30$KNN
results_50$KNN
results_80$KNN
results_110$KNN
confusionMatrix(results_110$SVM)  # if you want detailed performance


```
```{r}
results_30$RF
results_50$RF
results_80$RF
results_110$RF
```
```{r}
results_30$SVM
results_50$SVM
results_80$SVM
results_110$SVM
```
```{r}
# Get the top N genes for the best model
best_model <- results_110$RF  # Assuming Random Forest with top 50 genes performed the best

# Extract the relevant features from the test data
test_features <- t(expr_test[top_110, ])  # Transpose the test expression data for top 50 genes
test_data <- data.frame(test_features)

# Make predictions using the best model
predictions <- predict(best_model, newdata = test_data)

# Actual labels from the test data
actual_labels <- as.factor(metadata_test$grade)

# Confusion Matrix to see accuracy and other metrics
confusion_matrix <- confusionMatrix(predictions, actual_labels)
print(confusion_matrix)

```
# everything combination
```{r}

# 1. Expression sets
expr_list <- list(

  gse10810 = exprs(gse10810),
  gse17907 = exprs(gse17907),
  gse20711 = exprs(gse20711),
  gse42568 = exprs(gse42568),
  gse61304 = exprs(gse61304),
  gse15852 = exprs(gse15852)
)

# 2. Phenotype sets
pdata_list <- list(

  pdata10810,
  pdata17907,
  pdata20711,
  pdata42568,
  pdata61304,
  pdata15852
)

# 3. Fix phenotype rownames using geo_accession if present
pdata_list <- lapply(pdata_list, function(p) {
  if ("geo_accession" %in% colnames(p)) {
    rownames(p) <- p$geo_accession
  }
  return(p)
})

# Reassign corrected pdata

# 1. Assign pdata
pdata10810 <- pdata_list[[1]]
pdata17907 <- pdata_list[[2]]
pdata20711 <- pdata_list[[3]]
pdata42568 <- pdata_list[[4]]
pdata61304 <- pdata_list[[5]]
pdata15852 <- pdata_list[[6]]

# 2. Create pheno_list with dataset names
pheno_list <- list(
  gse10810 = pdata10810,
  gse17907 = pdata17907,
  gse20711 = pdata20711,
  gse42568 = pdata42568,
  gse61304 = pdata61304,
  gse15852 = pdata15852
)

# 3. Extract grade list and track batch
grade_list <- Map(function(expr, pheno, batch_name) {
  sample_names <- colnames(expr)
  matched_pheno <- pheno[sample_names, , drop = FALSE]
  grades <- matched_pheno$grade
  names(grades) <- sample_names
  # Track batch
  data.frame(
    sample = sample_names,
    grade = grades,
    batch = batch_name,
    stringsAsFactors = FALSE
  )
}, expr_list, pheno_list, names(pheno_list))

# 4. Combine all grade + batch info into metadata
metadata <- do.call(rbind, grade_list)

# 5. Clean sample names to remove prefixes (e.g., "gse10810.")
metadata$sample <- sub(".*\\.", "", metadata$sample)

# 6. Combine expression matrices
expr_dfs <- lapply(expr_list, function(mat) {
  df <- as.data.frame(mat)
  df$gene <- rownames(mat)
  df
})

merged_expr <- Reduce(function(x, y) full_join(x, y, by = "gene"), expr_dfs)
rownames(merged_expr) <- merged_expr$gene
merged_expr$gene <- NULL

# 7. Ensure metadata matches expression matrix columns
colnames(merged_expr) <- sub(".*\\.", "", colnames(merged_expr))  # Match cleaned sample names
metadata <- metadata[match(colnames(merged_expr), metadata$sample), ]

# 8. Final check
stopifnot(all(metadata$sample == colnames(merged_expr)))

# âœ… Outputs
metadata
dim(merged_expr)
table(metadata$batch)
table(metadata$grade)

summary(as.vector(merged_expr))

```
```{r}
metadata <- metadata[!is.na(metadata$grade), ]
metadata
# ðŸ§¼ Remove corresponding columns from merged_expr
merged_expr <- merged_expr[, metadata$sample]
anyNA(merged_expr)
sum(is.na(merged_expr))
merged_expr <- merged_expr[complete.cases(merged_expr), ]
merged_expr

table(metadata$grade)
```

```{r}


# Run PCA
pca <- prcomp(t(merged_expr), scale. = TRUE)

# Create a data frame for plotting
pca_df <- data.frame(
  PC1 = pca$x[, 1],
  PC2 = pca$x[, 2],
  batch = metadata$batch,
  grade = metadata$grade
)

# Plot PCA, color by batch
ggplot(pca_df, aes(x = PC1, y = PC2, color = batch)) +
  geom_point(size = 2) +
  theme_minimal() +
  labs(title = "PCA: Color by Batch")

# Optional: facet by condition
ggplot(pca_df, aes(x = PC1, y = PC2, color = grade)) +
  geom_point(size = 2) +
  facet_wrap(~batch) +
  theme_minimal() +
  labs(title = "PCA: Faceted by Batch")

```

```{r}
log_merged <- log2(merged_expr + 1)



merged_expr[merged_expr < 0] <- 0  # Replace negative values with 0


# Create DGEList object from raw counts
dge <- DGEList(counts = merged_expr)

# Normalize the counts (TMM method)
dge <- calcNormFactors(dge)

# Apply the normalization factors
normalized_expr <- cpm(dge, log = FALSE)  # Output in counts per million

# Log2 CPM transformation (recommended for limma)
log2_expr <- cpm(dge, log = TRUE)



train_idx <- sample(seq_len(ncol(normalized_expr)), size = 0.7 * ncol(normalized_expr))

# Create training and test sets
expr_train <- normalized_expr[, train_idx]
expr_test <- normalized_expr[, -train_idx]

metadata_train <- metadata[match(colnames(expr_train), metadata$sample), ]
metadata_test <- metadata[metadata$sample %in% colnames(expr_test), ]

# Reorder metadata_train to match expr_train sample order
# Remove genes with zero variance in any batch



```

```{r}
batch <- metadata_train$batch  # Replace 'batch' with the actual batch column name
grade <- factor(metadata_train$grade)  # Replace with actual condition column
mod <- model.matrix(~ grade)  # Model for the biological variable


remove_zero_var_genes <- function(expr, batch) {
  keep <- apply(expr, 1, function(gene) {
    all(tapply(gene, batch, function(x) var(x) > 0))
  })
  expr[keep, ]
}

expr_train_clean <- remove_zero_var_genes(expr_train, batch)
# Should return: Factor or atomic vector, length == ncol(expr_train)

# Perform ComBat batch correction
combat <- ComBat(dat = expr_train_clean, batch = batch, mod = mod)


# Check the dimensions of combat_train
dim(combat) 
```


```{r}
library(ggplot2)
library(reshape2)

# Function to run PCA and return a dataframe
get_pca_df <- function(expr_mat, metadata, prefix = "") {
  pca <- prcomp(t(expr_mat), scale. = TRUE)
  pca_df <- as.data.frame(pca$x[, 1:2])  # First two PCs
  pca_df$sample <- rownames(pca_df)
  pca_df <- merge(pca_df, metadata, by = "sample")
  colnames(pca_df)[1:3] <- paste0(prefix, c("PC1", "PC2", "sample"))
  return(pca_df)
}

# PCA before batch correction
pca_before <- get_pca_df(log2_expr, metadata, prefix = "before_")

# PCA after batch correction
pca_after <- get_pca_df(combat, metadata, prefix = "after_")


```

```{r}
# Plot before batch correction
ggplot(pca_before, aes(x = before_PC1, y = before_PC2, color = batch)) +
  geom_point(size = 2) +
  labs(title = "PCA Before Batch Correction", x = "PC1", y = "PC2") +
  theme_minimal()

# Plot after batch correction
ggplot(pca_after, aes(x = after_PC1, y = after_PC2, color = batch)) +
  geom_point(size = 2) +
  labs(title = "PCA After Batch Correction", x = "PC1", y = "PC2") +
  theme_minimal()

```


```{r}
library(smotefamily)

# Transpose so samples are rows
expr_t <- t(combat)
expr_df <- as.data.frame(expr_t)
expr_df$grade <- metadata_train$grade[match(rownames(expr_df), metadata_train$sample)]

# Convert grade to factor
expr_df$grade <- as.factor(expr_df$grade)

# Apply SMOTE (over-sampling only)
# dup_size controls how many synthetic samples to make per minority sample
smote_result <- SMOTE(X = expr_df[, -ncol(expr_df)],
                      target = expr_df$grade,
                      K = 5,
                      dup_size = 5)  # try 5â€“10

# SMOTE returns a list with $data
expr_smote <- smote_result$data

# Extract new metadata and expression matrix
metadata_train <- data.frame(
  sample = paste0("SMOTE_", seq_len(nrow(expr_smote))),
  grade = expr_smote$class
)

expr_balanced <- t(as.matrix(expr_smote[, -ncol(expr_smote)]))
colnames(expr_balanced) <- metadata_train$sample

stopifnot(all(colnames(expr_balanced) == metadata_train$sample))
table(metadata_train$grade)
```

```{r}
# Map grade levels to numeric trend
grade_map <- c("Normal" = 0, "Grade1" = 1, "Grade2" = 2, "Grade3" = 3)
grade_num <- grade_map[as.character(metadata_train$grade)]

design <- model.matrix(~ grade_num)  # includes intercept + trend

fit <- lmFit(expr_balanced, design)
fit <- eBayes(fit)

top_genes <- topTable(
  fit,
  coef = "grade_num",  # test for trend
  adjust = "BH",
  p.value = 0.05,      # FDR threshold
  lfc = 0.5,           # log2 fold-change threshold
  number = Inf
)

head(top_genes)
nrow(top_genes)  # number of significant genes

top_30 <- rownames(top_genes)[1:30]
top_50 <- rownames(top_genes)[1:50]
top_80 <- rownames(top_genes)[1:80]
top_110 <- rownames(top_genes)[1:110]

```



```{r}
# Labels (as factor for classification)
labels <- as.factor(metadata_train$grade)
evaluate_models <- function(feature_genes, expr_data, labels) {
  features <- t(expr_data[feature_genes, ])  # transpose: samples as rows
  data <- data.frame(features)
  data$label <- labels
  
  # Set up cross-validation
  control <- trainControl(method = "cv", number = 10)
  
  # KNN
  set.seed(1)
  knn_model <- train(label ~ ., data = data, method = "knn", trControl = control)
  
  # Random Forest
  set.seed(1)
  rf_model <- train(label ~ ., data = data, method = "rf", trControl = control)
  
  # SVM (linear kernel)
  set.seed(1)
  svm_model <- train(label ~ ., data = data, method = "svmLinear", trControl = control)
  
  list(
    KNN = knn_model,
    RF = rf_model,
    SVM = svm_model
  )
}


```




```{r}
results_30 <- evaluate_models(top_30, expr_balanced, labels)
results_50 <- evaluate_models(top_50, expr_balanced, labels)
results_80 <- evaluate_models(top_80, expr_balanced, labels)
results_110 <- evaluate_models(top_110, expr_balanced, labels)

```


```{r}
results_30$KNN
results_50$KNN
results_80$KNN
results_110$KNN
confusionMatrix(results_110$SVM)  # if you want detailed performance


```
```{r}
results_30$RF
results_50$RF
results_80$RF
results_110$RF
```
```{r}
results_30$SVM
results_50$SVM
results_80$SVM
results_110$SVM
```
```{r}
# Get the top N genes for the best model
best_model <- results_110$RF  # Assuming Random Forest with top 50 genes performed the best

# Extract the relevant features from the test data
test_features <- t(expr_test[top_110, ])  # Transpose the test expression data for top 50 genes
test_data <- data.frame(test_features)

# Make predictions using the best model
predictions <- predict(best_model, newdata = test_data)

# Actual labels from the test data
actual_labels <- as.factor(metadata_test$grade)

# Confusion Matrix to see accuracy and other metrics
confusion_matrix <- confusionMatrix(predictions, actual_labels)
print(confusion_matrix)

```


# gse15852 x gse10810
```{r}

# 1. Expression sets
expr_list <- list(

  gse10810 = exprs(gse10810),
  gse15852 = exprs(gse15852)
)

# 2. Phenotype sets
pdata_list <- list(

  pdata10810,
  pdata15852
)

# 3. Fix phenotype rownames using geo_accession if present
pdata_list <- lapply(pdata_list, function(p) {
  if ("geo_accession" %in% colnames(p)) {
    rownames(p) <- p$geo_accession
  }
  return(p)
})

# Reassign corrected pdata

# 1. Assign pdata
pdata10810 <- pdata_list[[1]]
pdata15852 <- pdata_list[[2]]

# 2. Create pheno_list with dataset names
pheno_list <- list(
  gse10810 = pdata10810,
  gse15852 = pdata15852
)

# 3. Extract grade list and track batch
grade_list <- Map(function(expr, pheno, batch_name) {
  sample_names <- colnames(expr)
  matched_pheno <- pheno[sample_names, , drop = FALSE]
  grades <- matched_pheno$grade
  names(grades) <- sample_names
  # Track batch
  data.frame(
    sample = sample_names,
    grade = grades,
    batch = batch_name,
    stringsAsFactors = FALSE
  )
}, expr_list, pheno_list, names(pheno_list))

# 4. Combine all grade + batch info into metadata
metadata <- do.call(rbind, grade_list)

# 5. Clean sample names to remove prefixes (e.g., "gse10810.")
metadata$sample <- sub(".*\\.", "", metadata$sample)

# 6. Combine expression matrices
expr_dfs <- lapply(expr_list, function(mat) {
  df <- as.data.frame(mat)
  df$gene <- rownames(mat)
  df
})

merged_expr <- Reduce(function(x, y) full_join(x, y, by = "gene"), expr_dfs)
rownames(merged_expr) <- merged_expr$gene
merged_expr$gene <- NULL

# 7. Ensure metadata matches expression matrix columns
colnames(merged_expr) <- sub(".*\\.", "", colnames(merged_expr))  # Match cleaned sample names
metadata <- metadata[match(colnames(merged_expr), metadata$sample), ]

# 8. Final check
stopifnot(all(metadata$sample == colnames(merged_expr)))

# âœ… Outputs
metadata
dim(merged_expr)
table(metadata$batch)
table(metadata$grade)

summary(as.vector(merged_expr))

```
```{r}
metadata <- metadata[!is.na(metadata$grade), ]
metadata
# ðŸ§¼ Remove corresponding columns from merged_expr
merged_expr <- merged_expr[, metadata$sample]
anyNA(merged_expr)
sum(is.na(merged_expr))
merged_expr <- merged_expr[complete.cases(merged_expr), ]
merged_expr

table(metadata$grade)
```

```{r}

# Run PCA
pca <- prcomp(t(merged_expr), scale. = TRUE)

# Create a data frame for plotting
pca_df <- data.frame(
  PC1 = pca$x[, 1],
  PC2 = pca$x[, 2],
  batch = metadata$batch,
  grade = metadata$grade
)

# Plot PCA, color by batch
ggplot(pca_df, aes(x = PC1, y = PC2, color = batch)) +
  geom_point(size = 2) +
  theme_minimal() +
  labs(title = "PCA: Color by Batch")

# Optional: facet by condition
ggplot(pca_df, aes(x = PC1, y = PC2, color = grade)) +
  geom_point(size = 2) +
  facet_wrap(~batch) +
  theme_minimal() +
  labs(title = "PCA: Faceted by Batch")

```

```{r}
log_merged <- log2(merged_expr + 1)



merged_expr[merged_expr < 0] <- 0  # Replace negative values with 0


# Create DGEList object from raw counts
dge <- DGEList(counts = merged_expr)

# Normalize the counts (TMM method)
dge <- calcNormFactors(dge)

# Apply the normalization factors
normalized_expr <- cpm(dge, log = FALSE)  # Output in counts per million

# Log2 CPM transformation (recommended for limma)
log2_expr <- cpm(dge, log = TRUE)



train_idx <- sample(seq_len(ncol(normalized_expr)), size = 0.7 * ncol(normalized_expr))

# Create training and test sets
expr_train <- normalized_expr[, train_idx]
expr_test <- normalized_expr[, -train_idx]

metadata_train <- metadata[match(colnames(expr_train), metadata$sample), ]
metadata_test <- metadata[metadata$sample %in% colnames(expr_test), ]

# Reorder metadata_train to match expr_train sample order
# Remove genes with zero variance in any batch



```

```{r}
batch <- metadata_train$batch  # Replace 'batch' with the actual batch column name
grade <- factor(metadata_train$grade)  # Replace with actual condition column
mod <- model.matrix(~ grade)  # Model for the biological variable


remove_zero_var_genes <- function(expr, batch) {
  keep <- apply(expr, 1, function(gene) {
    all(tapply(gene, batch, function(x) var(x) > 0))
  })
  expr[keep, ]
}

expr_train_clean <- remove_zero_var_genes(expr_train, batch)
# Should return: Factor or atomic vector, length == ncol(expr_train)

# Perform ComBat batch correction
combat <- ComBat(dat = expr_train_clean, batch = batch, mod = mod)


# Check the dimensions of combat_train
dim(combat) 
```


```{r}
library(ggplot2)
library(reshape2)

# Function to run PCA and return a dataframe
get_pca_df <- function(expr_mat, metadata, prefix = "") {
  pca <- prcomp(t(expr_mat), scale. = TRUE)
  pca_df <- as.data.frame(pca$x[, 1:2])  # First two PCs
  pca_df$sample <- rownames(pca_df)
  pca_df <- merge(pca_df, metadata, by = "sample")
  colnames(pca_df)[1:3] <- paste0(prefix, c("PC1", "PC2", "sample"))
  return(pca_df)
}

# PCA before batch correction
pca_before <- get_pca_df(log2_expr, metadata, prefix = "before_")

# PCA after batch correction
pca_after <- get_pca_df(combat, metadata, prefix = "after_")


```

```{r}
# Plot before batch correction
ggplot(pca_before, aes(x = before_PC1, y = before_PC2, color = batch)) +
  geom_point(size = 2) +
  labs(title = "PCA Before Batch Correction", x = "PC1", y = "PC2") +
  theme_minimal()

# Plot after batch correction
ggplot(pca_after, aes(x = after_PC1, y = after_PC2, color = batch)) +
  geom_point(size = 2) +
  labs(title = "PCA After Batch Correction", x = "PC1", y = "PC2") +
  theme_minimal()

```


```{r}
library(smotefamily)

# Transpose so samples are rows
expr_t <- t(combat)
expr_df <- as.data.frame(expr_t)
expr_df$grade <- metadata_train$grade[match(rownames(expr_df), metadata_train$sample)]

# Convert grade to factor
expr_df$grade <- as.factor(expr_df$grade)

# Apply SMOTE (over-sampling only)
# dup_size controls how many synthetic samples to make per minority sample
smote_result <- SMOTE(X = expr_df[, -ncol(expr_df)],
                      target = expr_df$grade,
                      K = 5,
                      dup_size = 5)  # try 5â€“10

# SMOTE returns a list with $data
expr_smote <- smote_result$data

# Extract new metadata and expression matrix
metadata_train <- data.frame(
  sample = paste0("SMOTE_", seq_len(nrow(expr_smote))),
  grade = expr_smote$class
)

expr_balanced <- t(as.matrix(expr_smote[, -ncol(expr_smote)]))
colnames(expr_balanced) <- metadata_train$sample

stopifnot(all(colnames(expr_balanced) == metadata_train$sample))
table(metadata_train$grade)
```

```{r}
# Map grade levels to numeric trend
grade_map <- c("Normal" = 0, "Grade1" = 1, "Grade2" = 2, "Grade3" = 3)
grade_num <- grade_map[as.character(metadata_train$grade)]

design <- model.matrix(~ grade_num)  # includes intercept + trend

fit <- lmFit(expr_balanced, design)
fit <- eBayes(fit)

top_genes <- topTable(
  fit,
  coef = "grade_num",  # test for trend
  adjust = "BH",
  p.value = 0.05,      # FDR threshold
  lfc = 0.5,           # log2 fold-change threshold
  number = Inf
)

head(top_genes)
nrow(top_genes)  # number of significant genes

top_30 <- rownames(top_genes)[1:30]
top_50 <- rownames(top_genes)[1:50]
top_80 <- rownames(top_genes)[1:80]
top_110 <- rownames(top_genes)[1:110]

```



```{r}
# Labels (as factor for classification)
labels <- as.factor(metadata_train$grade)
evaluate_models <- function(feature_genes, expr_data, labels) {
  features <- t(expr_data[feature_genes, ])  # transpose: samples as rows
  data <- data.frame(features)
  data$label <- labels
  
  # Set up cross-validation
  control <- trainControl(method = "cv", number = 10)
  
  # KNN
  set.seed(1)
  knn_model <- train(label ~ ., data = data, method = "knn", trControl = control)
  
  # Random Forest
  set.seed(1)
  rf_model <- train(label ~ ., data = data, method = "rf", trControl = control)
  
  # SVM (linear kernel)
  set.seed(1)
  svm_model <- train(label ~ ., data = data, method = "svmLinear", trControl = control)
  
  list(
    KNN = knn_model,
    RF = rf_model,
    SVM = svm_model
  )
}


```




```{r}
results_30 <- evaluate_models(top_30, expr_balanced, labels)
results_50 <- evaluate_models(top_50, expr_balanced, labels)
results_80 <- evaluate_models(top_80, expr_balanced, labels)
results_110 <- evaluate_models(top_110, expr_balanced, labels)

```


```{r}
results_30$KNN
results_50$KNN
results_80$KNN
results_110$KNN
confusionMatrix(results_110$SVM)  # if you want detailed performance


```

```{r}
results_30$RF
results_50$RF
results_80$RF
results_110$RF
```

```{r}
results_30$SVM
results_50$SVM
results_80$SVM
results_110$SVM
```

```{r}
# Get the top N genes for the best model
best_model <- results_110$KNN  # Assuming Random Forest with top 50 genes performed the best

# Extract the relevant features from the test data
test_features <- t(expr_test[top_110, ])  # Transpose the test expression data for top 50 genes
test_data <- data.frame(test_features)

# Make predictions using the best model
predictions <- predict(best_model, newdata = test_data)

# Actual labels from the test data
actual_labels <- as.factor(metadata_test$grade)

# Confusion Matrix to see accuracy and other metrics
confusion_matrix <- confusionMatrix(predictions, actual_labels)
print(confusion_matrix)
```
