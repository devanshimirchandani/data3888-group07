---
title: "finding summaru"
author: "T"
date: "2025-05-23"
output: html_document
---

```{r}
library(tidyverse)
library(reshape2)
```

# combined(GSE10810, GSE17907) findings summary

```{r}
library(dplyr)
library(reshape2)
library(ggplot2)

combine_metrics <- data.frame(
  Genes = rep(c(30, 50, 80, 110), each = 3),
  Model = rep(c("SVM", "KNN", "RF"), times = 4),
  Accuracy = c(0.714, 0.619, 0.714,
               0.667, 0.571, 0.667,
               0.524, 0.619, 0.762,
               0.667, 0.619, 0.762),
  Kappa = c(0.556, 0.455, 0.538,
            0.46, 0.376, 0.507,
            0.231, 0.477, 0.62,
            0.46, 0.481, 0.639),
  Macro_F1 = c(0.678, 0.641, 0.848,
               0.809, 0.778, 0.667,
               0.655, 0.702, 0.698,
               0.809, 0.733, 0.761),
  Precision = c(0.534, 0.531, 0.514,
                0.524, 0.389, 0.498,
                0.367, 0.583, 0.722,
                0.524, 0.667, 0.58),
  Recall = c(0.507, 0.451, 0.472,
             0.437, 0.389, 0.514,
             0.337, 0.486, 0.535,
             0.437, 0.486, 0.569),
  Sensitivity = c(0.507, 0.451, 0.472,
                  0.437, 0.389, 0.514,
                  0.337, 0.486, 0.535,
                  0.437, 0.486, 0.569),
  Specificity = c(0.889, 0.873, 0.884,
                  0.863, 0.852, 0.881,
                  0.806, 0.881, 0.902,
                  0.863, 0.883, 0.913),
  Balanced_Accuracy = c(0.698, 0.662, 0.678,
                        0.65, 0.62, 0.697,
                        0.572, 0.684, 0.718,
                        0.65, 0.685, 0.741)
)


# View the table
print(combine_metrics)

# Add an identifier for easier plotting
combine_metrics$Config <- paste(combine_metrics$Model, combine_metrics$Genes, sep = "_")

# Select top 5 models by Balanced Accuracy
top5 <- combine_metrics %>%
  arrange(desc(Balanced_Accuracy)) %>%
  head(5)

# Reshape to long format for ggplot
top5_long <- melt(top5, id.vars = c("Model", "Genes", "Config"))

# Plot heatmap
ggplot(top5_long, aes(x = variable, y = Config, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(option = "plasma", name = "Metric Value") +
  labs(title = "Performance Heatmap of Top 5 Models",
       x = "Metric",
       y = "Model (Config)") +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

# Best Model – RF110 

**Best Macro F1 Score (0.848)**

-   RF110 handles all classes well — Normal, Grade1, Grade2, and Grade3.

-   Macro F1 treats all classes equally, so this score shows RF110 doesn’t just perform well on one class — it's balanced across the board.

**High Accuracy (0.714)**

-   RF110 correctly predicted the class in over 71% of test cases.

-   Since the dataset is balanced, accuracy is a reliable indicator — and RF110 is one of the most accurate models overall.

**Strong Balanced Accuracy (0.678)**

-   Balanced Accuracy averages sensitivity (true positive rate) and specificity (true negative rate).

-   RF110 is reliable at detecting real positives and good at avoiding false alarms — important for medical decision-making.

**High Kappa Score (0.538)**

-   Kappa compares the model's predictions to what would be expected by random chance.

-   A score of 0.538 shows that RF110 has strong agreement with the actual labels and performs well above random guessing.

**Good Precision (0.514)**

-   When RF110 predicts a specific class (e.g., Grade3), it is often correct.

-   This helps minimize false positives, which is critical for avoiding unnecessary treatments.

**Good Recall (0.472)**

-   RF110 successfully identifies many of the actual positive cases.

-   Important in medical applications where missing a case (false negative) can have serious consequences.

**High Specificity (0.884)**

-   RF110 is highly effective at identifying negatives correctly (e.g., normal tissue).

-   This reduces the risk of overdiagnosis and unnecessary anxiety or procedures.

**Why RF110 is the Best Overall**

-   Best overall balance across key metrics, especially Macro F1.

-   High accuracy, precision, recall, and specificity make it strong across all performance areas.

-   Performs well across all classes, not just one — making it especially suitable for multiclass medical classification.

-   Its combination of accurate detection and low false alarm rate is ideal for sensitive and high-stakes domains like healthcare.

# GSE17907 findings summary

```{r}
library(ggplot2)
library(reshape2)
library(dplyr)

# Evaluation metrics for GSE17907 dataset
gse17907_metrics <- data.frame(
  Genes = rep(c(30, 50, 80, 110), each = 3),
  Model = rep(c("SVM", "KNN", "RF"), times = 4),
  Accuracy = c(0.5, 0.667, 0.583,
               0.583, 0.667, 0.583,
               0.667, 0.667, 0.583,
               0.583, 0.583, 0.583),
  Kappa = c(-0.029, 0.36, 0.143,
            0, 0.36, 0.143,
            0.262, 0.36, 0.143,
            0, 0.143, 0.143),
  Macro_F1 = c(0.706, 0.639, 0.686,
               0.737, 0.639, 0.686,
               0.722, 0.639, 0.686,
               0.737, 0.686, 0.686),
  Precision = c(0.3, 0.722, 0.533,
                0.583, 0.722, 0.533,
                0.818, 0.722, 0.533,
                0.583, 0.533, 0.533),
  Recall = c(0.214, 0.464, 0.339,
             0.25, 0.464, 0.339,
             0.375, 0.464, 0.339,
             0.25, 0.339, 0.339),
  Sensitivity = c(0.214, 0.464, 0.339,
                  0.25, 0.464, 0.339,
                  0.375, 0.464, 0.339,
                  0.25, 0.339, 0.339),
  Specificity = c(0.75, 0.825, 0.775,
                  0.75, 0.825, 0.775,
                  0.8, 0.825, 0.775,
                  0.75, 0.775, 0.775),
  Balanced_Accuracy = c(0.482, 0.645, 0.557,
                        0.5, 0.645, 0.557,
                        0.588, 0.645, 0.557,
                        0.5, 0.557, 0.557)
)

# Add unique Config column
gse17907_metrics$Config <- paste(gse17907_metrics$Model, gse17907_metrics$Genes, sep = "_")

# Remove duplicated rows just in case (optional but safe)
gse17907_metrics <- distinct(gse17907_metrics)

# Select top 5 *distinct* models by Balanced Accuracy
top5 <- gse17907_metrics %>%
  arrange(desc(Balanced_Accuracy)) %>%
  slice_head(n = 5)

# Reshape to long format for heatmap
top5_long <- melt(top5, id.vars = c("Model", "Genes", "Config"))

# Plot heatmap
ggplot(top5_long, aes(x = variable, y = Config, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(option = "plasma", name = "Metric Value") +
  labs(title = "Performance Heatmap of Top 5 Models",
       x = "Metric",
       y = "Model (Config)") +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

# Best Model – KNN (Top30/50/80 genes)

**Strong Accuracy (0.667)**

-   Makes about 2 out of 3 predictions correctly.
-   Matches the top performers in this dataset.

**Highest Kappa (0.360)**

-   KNN predictions agree with true labels much more than random chance.

**Good Macro F1 Score (0.639)**

-   Indicates balanced performance across all grades.
-   No single class is dominating the results — important for fairness in medical data.

**High Precision (0.722)**

-   When KNN predicts a specific grade, it's usually right.
-   
-   Helps avoid false positives, like overdiagnosing a cancer grade.

**Reasonable Recall (0.464)**

-   KNN finds about 46% of all actual positive cases.
-   It may miss some positives, but it outperforms other models here.

**Highest Specificity (0.825)**

-   Great at identifying true negatives — important to avoid unnecessary treatment.

**Best Balanced Accuracy (0.645)**

-   Combines recall and specificity — a balanced view.

-   Shows the model is not biased toward only positive or negative predictions.

**Why KNN is Best for GSE17907**

-   It outperforms SVM and RF on every metric except F1 (which SVM slightly improves).
-   Delivers consistent results across multiple top gene sets.
-   Especially strong in precision, specificity, and overall balanced performance — key for medical diagnostics.

# GSE1582 findings summary

```{r}
library(ggplot2)
library(reshape2)
library(dplyr)

# Evaluation metrics from confusion matrices
gse17907_metrics <- data.frame(
  Genes = rep(c(30, 50, 80, 110), each = 3),
  Model = rep(c("SVM", "KNN", "RF"), times = 4),
  Accuracy = c(0.579, 0.579, 0.474,
               0.474, 0.526, 0.579,
               0.579, 0.579, 0.526,
               0.684, 0.579, 0.526),
  Kappa = c(0.321, 0.318, 0.055,
            0.021, 0.136, 0.306,
            0.290, 0.248, 0.153,
            0.477, 0.312, 0.153),
  Macro_F1 = c(0.593, 0.681, 0.474,
               0.667, 0.489, 0.697,
               0.723, 0.610, 0.485,
               0.731, 0.631, 0.570),
  Precision = c(0.583, 0.317, 0.490,
                0.250, 0.515, 0.341,
                0.524, 0.615, 0.448,
                0.788, 0.571, 0.583),
  Recall = c(0.461, 0.372, 0.272,
             0.250, 0.300, 0.372,
             0.372, 0.350, 0.300,
             0.539, 0.447, 0.322),
  Sensitivity = c(0.461, 0.372, 0.272,
                  0.250, 0.300, 0.372,
                  0.372, 0.350, 0.300,
                  0.539, 0.447, 0.322),
  Specificity = c(0.824, 0.834, 0.760,
                  0.757, 0.782, 0.827,
                  0.819, 0.807, 0.789,
                  0.857, 0.826, 0.782),
  Balanced_Accuracy = c(0.642, 0.603, 0.516,
                        0.504, 0.541, 0.600,
                        0.595, 0.579, 0.545,
                        0.698, 0.637, 0.552)
)

# Add Config column
gse17907_metrics$Config <- paste(gse17907_metrics$Model, gse17907_metrics$Genes, sep = "_")

# Select top 5 models by Balanced Accuracy
top5 <- gse17907_metrics %>%
  arrange(desc(Balanced_Accuracy)) %>%
  head(5)

# Reshape to long format for heatmap
top5_long <- melt(top5, id.vars = c("Model", "Genes", "Config"))

# Plot heatmap
ggplot(top5_long, aes(x = variable, y = Config, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(option = "plasma", name = "Metric Value") +
  labs(title = "Performance Heatmap of Top 5 Models",
       x = "Metric",
       y = "Model (Config)") +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

# Best Model – SVM (Top110 genes)

**Strong Accuracy (0.684)**

-   Correctly classifies about 68% of samples, outperforming others in this dataset.

**Highest Kappa (0.477)**

-   Shows substantial agreement between predictions and true labels beyond random chance, indicating reliable classification.

**Good Macro F1 Score (0.731)**

-   Balances precision and recall well across all grades, suggesting consistent performance on each class.

**High Precision (0.788)**

-   When SVM predicts a specific grade, it is usually correct, reducing the risk of false positives, which is crucial in medical diagnosis.

**Reasonable Recall (0.539)**

-   Finds about 54% of all actual positive cases, a good balance that helps detect many true positives while avoiding excessive false alarms.

**Highest Specificity (0.857)**

-   Excellent at correctly identifying true negatives, helping to prevent unnecessary treatments or interventions.

**Best Balanced Accuracy (0.698)**

-   Combines recall and specificity effectively, showing the model is well-balanced and unbiased toward any class.

**Why SVM is Best for GSE15852**

-   Outperforms KNN and RF on most metrics, especially precision, specificity, and overall balanced accuracy.

-   Consistently strong across the largest gene set tested, indicating stability and robustness.

-   Its balance between sensitivity and specificity is ideal for medical diagnostics where both false negatives and false positives carry serious consequences.
